{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from load_data import load\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv1D, Add, Reshape\n",
    "from keras.layers import AveragePooling2D, UpSampling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2DTranspose\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "import datetime\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "58863 sequences were uploaded\n",
      "\n",
      "Maximum sequence length in is 308\n",
      "Maximum sequence length out is 308\n",
      "\n",
      "Converting to one-hot...\n",
      "Done\n",
      "Converting to one-hot...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "[X_train,Y_train,X_test,Y_test] = load(\"blast_tab_1hit.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55996 training examples\n",
      "There are 2867 testing examples\n",
      "There are 4 classes: A, C, G, T\n",
      "The longest sequence is 308 nucleotides long\n",
      "(55996, 4, 308, 1)\n"
     ]
    }
   ],
   "source": [
    "m = X_train.shape[0]\n",
    "print(\"There are \" + str(m) + \" training examples\")\n",
    "print(\"There are \" + str(X_test.shape[0]) + \" testing examples\")\n",
    "print(\"There are \" + str(X_train.shape[1]) + \" classes: A, C, G, T\")\n",
    "max_length = max(X_train.shape[2],X_test.shape[2])\n",
    "print(\"The longest sequence is \" + str(max_length) + \" nucleotides long\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting...\n",
      "finished X\n",
      "finished Y\n"
     ]
    }
   ],
   "source": [
    "print('Permuting...')\n",
    "np.random.seed(0)\n",
    "rand_perm = np.random.rand(m).argsort()\n",
    "np.take(X_train,rand_perm,axis=0,out=X_train)\n",
    "print(\"finished X\")\n",
    "np.take(Y_train,rand_perm,axis=0,out=Y_train)\n",
    "print(\"finished Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Visualize data sets to ensure they appear as anticipated\n",
    "sample = 300\n",
    "print(X_train[sample,:,10:30,0])\n",
    "print(Y_train[sample,:,10:30,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = 16\n",
    "input_nc = 1\n",
    "output_nc = 1\n",
    "n_blocks_gen = 9\n",
    "\n",
    "# started from: https://blog.sicara.com/keras-generative-adversarial-networks-image-deblurring-45e3ab6977b5\n",
    "def Model_1(input_shape):\n",
    "    \"\"\"Build generator architecture.\"\"\"\n",
    "    # Current version : ResNet block\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # X = ZeroPadding2D((0, 3))(X_input) # allows 'valid' in conv0 to keep length and collapse one-hot\n",
    "\n",
    "    X = Conv2D(128, (4, 7), strides = (1, 1), padding = 'same', name = 'conv0')(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # X = Conv2D(64, (1, 7), strides = (1, 1), padding = 'same', name = 'conv1')(X)\n",
    "    # X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    # X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(64, (1, 7), strides = (1, 1), padding = 'same', name = 'conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Dropout(0.3, name = 'dropout')(X)\n",
    "   \n",
    "    X = Conv2D(32, (1, 7), strides = (1, 1), padding = 'same', name = 'conv3')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # X = Conv2D(4, (1, 1), strides = (1, 1), padding = 'same', data_format = 'channels_first', name = 'conv4')(X)\n",
    "    # X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(1, (1, 1), strides = (1, 1), padding = 'same', name = 'conv5')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn5')(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X, name='Model_1')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        (None, 4, 308, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 4, 308, 128)       3712      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 4, 308, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 4, 308, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 4, 308, 64)        57408     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 4, 308, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 4, 308, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 308, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 4, 308, 32)        14368     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 4, 308, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 4, 308, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 4, 308, 1)         33        \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 4, 308, 1)         4         \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4, 308, 1)         0         \n",
      "=================================================================\n",
      "Total params: 76,421\n",
      "Trainable params: 75,971\n",
      "Non-trainable params: 450\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "myModel = Model_1((4,max_length,1))\n",
    "print(myModel.summary())\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "myModel.compile(optimizer=\"Adam\", loss=\"mean_squared_error\", metrics = [\"accuracy\"])\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  150/55996 [..............................] - ETA: 27:47 - loss: 0.0028 - acc: 0.9976"
     ]
    }
   ],
   "source": [
    "myModel.fit(x = X_train, y = Y_train, epochs = 3, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = myModel.predict(x = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The noise was at nucleotide number 200\n",
      "The predictions from 197 to 202 are: \n",
      "[[0.02226665 0.02344638 0.02345594 0.02379335 0.02287278 0.02382558]\n",
      " [0.9848375  0.02370751 0.02285885 0.9902678  0.961254   0.9869472 ]\n",
      " [0.02335632 0.9863687  0.98482937 0.0231421  0.02286356 0.02333473]\n",
      " [0.02288348 0.02265301 0.02258126 0.02320942 0.02342632 0.02304558]]\n",
      "The true denoised nucleotides from 197 to 202 are: \n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "The input nucleotides from 197 to 202 were: \n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Change n to view the predictions, true sequence, and input sequence for a given sample\n",
    "n = 0\n",
    "samp_n_pred = preds[n,0:4,:,0]\n",
    "samp_n_in = X_test[n,0:4,:,0]\n",
    "samp_n_true = Y_test[n,0:4,:,0]\n",
    "noise = np.argmax(np.sum(np.square(samp_n_in - samp_n_true),axis=0))\n",
    "print(\"The noise was at nucleotide number \" + str(noise))\n",
    "print(\"The predictions from \" + str(noise-3) + \" to \" + str(noise+2) + \" are: \")\n",
    "print(preds[n,0:4,noise-3:noise+3,0])\n",
    "print(\"The true denoised nucleotides from \" + str(noise-3) + \" to \" + str(noise+2) + \" are: \")\n",
    "print(Y_test[n,0:4,noise-3:noise+3,0])\n",
    "print(\"The input nucleotides from \" + str(noise-3) + \" to \" + str(noise+2) + \" were: \")\n",
    "print(X_test[n,0:4,noise-3:noise+3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867/2867 [==============================] - 28s 10ms/step\n",
      "[0.002921829963272504, 0.9973582580690813]\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = myModel.evaluate(X_test, Y_test)\n",
    "print(loss_and_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./convWeights/0517-0911.hdf5\n"
     ]
    }
   ],
   "source": [
    "currtime = datetime.datetime.now()\n",
    "fname = \"./convWeights/\" + currtime.strftime(\"%m%d-%H%M\") + \".hdf5\"\n",
    "myModel.save_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.load_weights(\"./convWeights/0517-0842.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
