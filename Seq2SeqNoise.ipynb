{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import loads done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import History \n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Concatenate\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from termcolor import colored\n",
    "print(\"import loads done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [1], [-1], [-1]]\n",
      "[[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]]\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "l= []\n",
    "l.append([1])\n",
    "l.append([1])\n",
    "l.append([-1])\n",
    "l.append([-1])\n",
    "print(l)\n",
    "newl= np.array(l)\n",
    "print(newl)\n",
    "print(newl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "# UPLOAD DATA\n",
    "# (each user should put datafiles in this directory on their computer)\n",
    "datapath = \"blast_tab_1hit.out\"\n",
    "file = open(datapath, 'r')\n",
    "\n",
    "same_entries = []\n",
    "diff_entries = []\n",
    "train_entries=[]\n",
    "test_entries=[]\n",
    "val_entries=[]\n",
    "max_length_in = 0\n",
    "max_length_out = 0\n",
    "count_diff_entries_train=0\n",
    "count_same_entries_train=0\n",
    "count_diff_entries_val=0\n",
    "count_same_entries_val=0\n",
    "count_diff_entries_test=0\n",
    "count_same_entries_test=0\n",
    "y_train=[]\n",
    "y_val=[]\n",
    "y_test=[]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for ln in file:\n",
    "    toks = ln.split('\\t')\n",
    "    rand_num= np.random.random()\n",
    "    \n",
    "    max_length_in = max(max_length_in,len(toks[2]))\n",
    "    max_length_out = max(max_length_out,len(toks[3]))\n",
    "    if(toks[2] != toks[3]):\n",
    "        if rand_num < 0.95:\n",
    "            train_entries.append([toks[2], toks[3]])\n",
    "            count_diff_entries_train += 1\n",
    "            y_train.append([1])\n",
    "        elif rand_num <0.975:\n",
    "            test_entries.append([toks[2], toks[3]])\n",
    "            count_diff_entries_test += 1\n",
    "            y_test.append([1])\n",
    "        else:\n",
    "            val_entries.append([toks[2], toks[3]])\n",
    "            count_diff_entries_val += 1\n",
    "            y_val.append([1])\n",
    "        \n",
    "    if toks[2] == toks[3]:\n",
    "        if rand_num > 0.975:\n",
    "            val_entries.append([toks[2], toks[3]])\n",
    "            count_same_entries_val += 1\n",
    "            y_val.append([-1])\n",
    "        elif rand_num > 0.95:\n",
    "            test_entries.append([toks[2], toks[3]])\n",
    "            count_same_entries_test += 1\n",
    "            y_test.append([-1])\n",
    "        elif rand_num > 0.9:\n",
    "            train_entries.append([toks[2], toks[3]])\n",
    "            count_same_entries_train += 1\n",
    "            y_train.append([-1])\n",
    "        #same_entries.append([toks[2], toks[3]])\n",
    "    #else:\n",
    "        #diff_entries.append([toks[2], toks[3]])\n",
    "\n",
    "file.close()\n",
    "#num_entries = len(same_entries) + len(diff_entries)\n",
    "\n",
    "y_train_noise=np.array(y_train)\n",
    "y_val_noise= np.array(y_val)\n",
    "y_test_noise=np.array(y_test)\n",
    "#display train, test, val set\n",
    "#print(\"train\")\n",
    "#print(train_entries[2])\n",
    "#print(\"val\")\n",
    "#print(val_entries[2])\n",
    "#print(\"test\")\n",
    "#print(test_entries[2])\n",
    "\n",
    "#diff_entries_input = [entry[0] for entry in diff_entries]\n",
    "#diff_entries_output = [entry[1] for entry in diff_entries]\n",
    "#same_entries_input = [entry[0] for entry in same_entries]\n",
    "#same_entries_output = [entry[1] for entry in same_entries]\n",
    "#diff_entries_output = [(\"\\t\" + entry[1] + \"\\n\") for entry in diff_entries] #use '\\t' as start character and '\\n' as end character\n",
    "#Visualize\n",
    "#diff_entries_output[1]\n",
    "one_hot_input = {'A': 0, 'T': 1, 'C': 2, 'G': 3, '-': 4}\n",
    "one_hot_output = {'A': 0, 'T': 1, 'C': 2, 'G': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shapes\n",
      "(77510, 1)\n",
      "(12269, 1)\n",
      "(12107, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"y shapes\")\n",
    "print(y_train_noise.shape)\n",
    "print(y_val_noise.shape)\n",
    "print(y_test_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len 77510\n",
      "val len 12269\n",
      "tets len 12107\n",
      "diff entries in train 55906\n",
      "same entries train 21604\n",
      "diff entries in val 1450\n",
      "same entries val 10819\n",
      "diff entries in test 1507\n",
      "same entries test 10600\n",
      "total train + dev + test\n",
      "101886\n",
      "max len in 351\n",
      "max len out 351\n",
      "one train entry ['ACAGAGGGGGCAAGCGTTGTCCGGAGTTACTGGGCGTAAAGGGCGCGCAGGCGGTGGGCTGCGTCGGCGCTGAAAGCGCCCCGCTTAACGGGGCGAGGCGCGCCGATACGAGTCCACTCGAGGCAAGCAGAGGGTGGCGGAATTCCGGGTGGAGTGGTGAAATGCGTAGAGATCCGGAGGAACGCCGGTGGGGAAGCCGGCCACCTGGGCTTGACCTGACGCTGCGGCGCGACAGCGTGGGGAGCAAACCG', 'ACAGAGGGGGCAAGCGTTGTCCGGAGTTACTGGGCGTAAAGGGCGCGCAGGCGGTGGGCTGCGTCGGCGCTGAAAGCGCCCCGCTTAACGGGGCGAGGCGCGCCGATACGAGTCCACTCGAGGCAAGCAGAGGGTGGCGGAATTCCGGGTGGAGCGGTGAAATGCGTAGAGATCCGGAGGAACGCCGGTGGGGAAGCCGGCCACCTGGGCTTGACCTGACGCTGCGGCGCGACAGCGTGGGGAGCAAACCG']\n"
     ]
    }
   ],
   "source": [
    "#prints\n",
    "print(\"train len\",len(train_entries))\n",
    "print(\"val len\",len(val_entries))\n",
    "print(\"tets len\",len(test_entries))\n",
    "print(\"diff entries in train\", count_diff_entries_train)\n",
    "print(\"same entries train\", count_same_entries_train)\n",
    "print(\"diff entries in val\", count_diff_entries_val)\n",
    "print(\"same entries val\", count_same_entries_val)\n",
    "print(\"diff entries in test\", count_diff_entries_test)\n",
    "print(\"same entries test\", count_same_entries_test)\n",
    "\n",
    "print(\"total train + dev + test\")\n",
    "print(len(train_entries)+ len(val_entries)+ len(test_entries))\n",
    "\n",
    "print(\"max len in\",max_length_in)\n",
    "print(\"max len out\", max_length_out)\n",
    "\n",
    "print(\"one train entry\",train_entries[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs= [entry[0] for entry in train_entries]\n",
    "output_seqs= [entry[1] for entry in train_entries]\n",
    "val_input_seqs= [entry[0] for entry in val_entries]\n",
    "val_output_seqs= [entry[1] for entry in val_entries]\n",
    "test_input_seqs= [entry[0] for entry in test_entries]\n",
    "test_output_seqs= [entry[1] for entry in test_entries]\n",
    "#display\n",
    "#print(\"train in\")\n",
    "#print(input_seqs[100])\n",
    "#print(\"val in\")\n",
    "#print(val_input_seqs[100])\n",
    "#print(\"test in\")\n",
    "#print(test_input_seqs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77510\n",
      "77510\n",
      "12269\n",
      "12107\n"
     ]
    }
   ],
   "source": [
    "print(len(input_seqs))\n",
    "print(len(output_seqs))\n",
    "print(len(val_input_seqs))\n",
    "print(len(test_input_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels len 77510\n",
      "val labels len 12269\n",
      "test labels len 12107\n"
     ]
    }
   ],
   "source": [
    "labels_train=np.array(y_train_noise)\n",
    "labels_val= np.array(y_val_noise)\n",
    "labels_test= np.array(y_test_noise)\n",
    "#labels_train= [[1]]* count_diff_entries_train + [[-1]]*count_same_entries_train\n",
    "#labels_val= [[1]]* count_diff_entries_val + [[-1]]*count_same_entries_val\n",
    "#labels_test= [[1]]* count_diff_entries_test + [[-1]]*count_same_entries_test\n",
    "print(\"train labels len\",len(labels_train))\n",
    "print(\"val labels len\",len(labels_val))\n",
    "print(\"test labels len\",len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#print samples train, val, test labels\n",
    "print(labels_train)\n",
    "#print(labels_val[0:15])\n",
    "#print(labels_test[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenghts:\n",
      "input_seqs-> 77510\n",
      "output_seqs -> 77510\n",
      "labels train--> 77510\n"
     ]
    }
   ],
   "source": [
    "c = list(zip(input_seqs, output_seqs, labels_train))\n",
    "#seed = 123\n",
    "#random.seed(seed)\n",
    "#random.shuffle(c)\n",
    "input_seqs, output_seqs, labels_train = zip(*c)\n",
    "print(\"lenghts:\")\n",
    "print(\"input_seqs->\",len(input_seqs))\n",
    "print(\"output_seqs ->\", len(output_seqs))\n",
    "print(\"labels train-->\", len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenghts:\n",
      "input_seqs-> 12269\n",
      "output_seqs -> 12269\n",
      "labels train--> 12269\n"
     ]
    }
   ],
   "source": [
    "c = list(zip(val_input_seqs, val_output_seqs, labels_val))\n",
    "#seed = 123\n",
    "#random.seed(seed)\n",
    "#random.shuffle(c)\n",
    "val_input_seqs, val_output_seqs, labels_val = zip(*c)\n",
    "print(\"lenghts:\")\n",
    "print(\"input_seqs->\",len(val_input_seqs))\n",
    "print(\"output_seqs ->\", len(val_output_seqs))\n",
    "print(\"labels train-->\", len(labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenghts:\n",
      "input_seqs-> 12107\n",
      "output_seqs -> 12107\n",
      "labels train--> 12107\n"
     ]
    }
   ],
   "source": [
    "c = list(zip(test_input_seqs, test_output_seqs, labels_test))\n",
    "#seed = 123\n",
    "#random.seed(seed)\n",
    "#random.shuffle(c)\n",
    "test_input_seqs, test_output_seqs, labels_test = zip(*c)\n",
    "print(\"lenghts:\")\n",
    "print(\"input_seqs->\",len(test_input_seqs))\n",
    "print(\"output_seqs ->\", len(test_output_seqs))\n",
    "print(\"labels train-->\", len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108863\n",
      "108863\n"
     ]
    }
   ],
   "source": [
    "#NOT TO RUN\n",
    "#data massage\n",
    "#numSameEntries = 50000\n",
    "#input_seqs = diff_entries_input + same_entries_input[0:numSameEntries]\n",
    "#output_seqs = diff_entries_output + same_entries_output[0:numSameEntries]\n",
    "#labels = [[1]] * len(diff_entries_input) + [[-1]] * numSameEntries\n",
    "#print(len(labels))\n",
    "#print(len(input_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments for below cell\n",
      "input seqs len:  77510\n",
      "max len in:  351\n",
      "one hot inp len:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"arguments for below cell\")\n",
    "print(\"input seqs len: \", len(input_seqs))\n",
    "#print(\"input seqs shape: \", input_seqs.shape)\n",
    "print(\"max len in: \", max_length_in)\n",
    "print(\"one hot inp len: \", len(one_hot_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode train data\n",
    "\n",
    "#ENCODE\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_seqs), max_length_in, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_seqs, output_seqs) in enumerate(zip(input_seqs, output_seqs)):\n",
    "    for t, char in enumerate(input_seqs):\n",
    "        #print(t)\n",
    "        encoder_input_data[i, t, one_hot_input[char]] = 1.\n",
    "    for t, char in enumerate(output_seqs):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, one_hot_input[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, one_hot_input[char]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77510, 351, 5)\n",
      "(77510, 351, 5)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode val data\n",
    "\n",
    "#ENCODE\n",
    "encoder_input_data_val = np.zeros(\n",
    "    (len(val_input_seqs), max_length_in, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_input_data_val = np.zeros(\n",
    "    (len(val_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_target_data_val = np.zeros(\n",
    "    (len(val_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (val_input_seqs, val_output_seqs) in enumerate(zip(val_input_seqs, val_output_seqs)):\n",
    "    for t, char in enumerate(val_input_seqs):\n",
    "        #print(t)\n",
    "        encoder_input_data_val[i, t, one_hot_input[char]] = 1.\n",
    "    for t, char in enumerate(val_output_seqs):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_val[i, t, one_hot_input[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data_val[i, t - 1, one_hot_input[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12269, 351, 5)\n",
      "(12269, 351, 5)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_val.shape)\n",
    "print(decoder_input_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode test data\n",
    "\n",
    "#ENCODE\n",
    "encoder_input_data_test = np.zeros(\n",
    "    (len(test_input_seqs), max_length_in, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_input_data_test = np.zeros(\n",
    "    (len(test_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_target_data_test = np.zeros(\n",
    "    (len(test_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (test_input_seqs, test_output_seqs) in enumerate(zip(test_input_seqs, test_output_seqs)):\n",
    "    for t, char in enumerate(test_input_seqs):\n",
    "        #print(t)\n",
    "        encoder_input_data_test[i, t, one_hot_input[char]] = 1.\n",
    "    for t, char in enumerate(test_output_seqs):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_test[i, t, one_hot_input[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data_test[i, t - 1, one_hot_input[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12107, 351, 5)\n",
      "(12107, 351, 5)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_test.shape)\n",
    "print(decoder_input_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters to change\n",
    "num_encoder_tokens = len(one_hot_input)\n",
    "num_decoder_tokens = len(one_hot_input)\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Tanh:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "e_lstm_1 = Bidirectional(LSTM(latent_dim, return_sequences = True))(encoder_inputs)\n",
    "e_dropout = Dropout(0.5)(e_lstm_1)\n",
    "e_lstm_2, fh2, fc2, bh2, bc2 = Bidirectional(LSTM(latent_dim, return_sequences = True, return_state=True))(e_dropout)\n",
    "#e_lstm_3 = Bidirectional(LSTM(latent_dim, return_sequences = True))\n",
    "h2=Concatenate()([fh2,bh2])\n",
    "c2=Concatenate()([fc2,bc2])\n",
    "\n",
    "#output = TimeDistributed(Dense(num_decoder_tokens, activation = \"softmax\"))(e_lstm_2)\n",
    "noise_class = Dense(1, activation = \"tanh\")(Concatenate()([h2, c2]))\n",
    "#noise_class = Activation(\"tanh\")(noise_class)\n",
    "print(noise_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 5)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 200)    84800       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 200)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, None, 200),  240800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 400)          0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            401         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 326,001\n",
      "Trainable params: 326,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Model(encoder_inputs, noise_class)\n",
    "model.summary()\n",
    "\n",
    "#np.array(labels)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.6989 - acc: 0.4210 - val_loss: 1.1429 - val_acc: 0.1560\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.15600, saving model to seqWeights/LSTM-test-01-0.16.hdf5\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.6921 - acc: 0.4830 - val_loss: 0.9807 - val_acc: 0.1470\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.15600\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.6920 - acc: 0.5220 - val_loss: 0.5631 - val_acc: 0.0290\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.15600\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.6768 - acc: 0.6320 - val_loss: 0.6417 - val_acc: 0.0890\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.15600\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.6664 - acc: 0.4740 - val_loss: 1.4170 - val_acc: 0.1360\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.15600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18bfcc908d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Model(encoder_inputs, noise_class)\n",
    "\n",
    "#model.load_weights(\"seqWeights/LSTM-comboseqs-dropout0.5-manytomany-01-0.82.hdf5\")\n",
    "adam = keras.optimizers.Adam(lr = .001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer= adam, loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = History()\n",
    "filepath=\"seqWeights/LSTM-test-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "#Change numExamples to change training over full dataset\n",
    "numExamples = 1000\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "#output_seqs = decoder_input_data[0:numExamples, :, :]\n",
    "#y = output_seqs.reshape(numExamples, output_seqs.shape[1], 1)\n",
    "#model.fit(encoder_input_data[0:numExamples, :, :],\n",
    "#          np.array(labels)[0:numExamples],\n",
    "#          batch_size=batch_size,\n",
    "#          epochs=epochs,\n",
    "#          validation_split=0.2, verbose = 1,\n",
    "#         callbacks = [history, checkpoint])\n",
    "\n",
    "model.fit(encoder_input_data[0:numExamples, :, :],\n",
    "          np.array(labels_train)[0:numExamples],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(encoder_input_data_val[0:numExamples,:,:], np.array(labels_val)[0:numExamples]), verbose = 1,\n",
    "         callbacks = [history, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=np.array(labels_train)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "score= model.evaluate(encoder_input_data_test[0:numExamples,:,:], np.array(labels_test)[0:numExamples], verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores\n",
      "[0.4368599247932434, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"scores\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83007616]\n",
      " [0.7361489 ]\n",
      " [0.55771655]\n",
      " [0.69080997]\n",
      " [0.4479485 ]\n",
      " [0.55046546]\n",
      " [0.67283136]\n",
      " [0.72490335]\n",
      " [0.60135865]\n",
      " [0.44794852]]\n",
      "[[-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(encoder_input_data_test[0:10, :, :]))\n",
    "print(np.array(labels_test)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
