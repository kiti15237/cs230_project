{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import loads done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import History \n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Concatenate\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from termcolor import colored\n",
    "print(\"import loads done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "# UPLOAD DATA\n",
    "# (each user should put datafiles in this directory on their computer)\n",
    "datapath = \"blast_tab_1hit.out\"\n",
    "file = open(datapath, 'r')\n",
    "\n",
    "same_entries = []\n",
    "diff_entries = []\n",
    "train_entries=[]\n",
    "test_entries=[]\n",
    "val_entries=[]\n",
    "max_length_in = 0\n",
    "max_length_out = 0\n",
    "count_diff_entries_train=0\n",
    "count_same_entries_train=0\n",
    "count_diff_entries_val=0\n",
    "count_same_entries_val=0\n",
    "count_diff_entries_test=0\n",
    "count_same_entries_test=0\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for ln in file:\n",
    "    toks = ln.split('\\t')\n",
    "    rand_num= np.random.random()\n",
    "    \n",
    "    max_length_in = max(max_length_in,len(toks[2]))\n",
    "    max_length_out = max(max_length_out,len(toks[3]))\n",
    "    if(toks[2] != toks[3]):\n",
    "        if rand_num < 0.95:\n",
    "            train_entries.append([toks[2], toks[3]])\n",
    "            count_diff_entries_train += 1\n",
    "        elif rand_num <0.975:\n",
    "            test_entries.append([toks[2], toks[3]])\n",
    "            count_diff_entries_test += 1\n",
    "        else:\n",
    "            val_entries.append([toks[2], toks[3]])\n",
    "            count_diff_entries_val += 1\n",
    "        \n",
    "    if toks[2] == toks[3]:\n",
    "        if rand_num > 0.975:\n",
    "            val_entries.append([toks[2], toks[3]])\n",
    "            count_same_entries_val += 1\n",
    "        elif rand_num > 0.95:\n",
    "            test_entries.append([toks[2], toks[3]])\n",
    "            count_same_entries_test += 1\n",
    "        elif rand_num > 0.9:\n",
    "            train_entries.append([toks[2], toks[3]])\n",
    "            count_same_entries_train += 1\n",
    "        #same_entries.append([toks[2], toks[3]])\n",
    "    #else:\n",
    "        #diff_entries.append([toks[2], toks[3]])\n",
    "\n",
    "file.close()\n",
    "#num_entries = len(same_entries) + len(diff_entries)\n",
    "\n",
    "#display train, test, val set\n",
    "#print(\"train\")\n",
    "#print(train_entries[2])\n",
    "#print(\"val\")\n",
    "#print(val_entries[2])\n",
    "#print(\"test\")\n",
    "#print(test_entries[2])\n",
    "\n",
    "\n",
    "#diff_entries_output[1]\n",
    "one_hot_input = {'A': 0, 'T': 1, 'C': 2, 'G': 3, '-': 4}\n",
    "one_hot_output = {'A': 0, 'T': 1, 'C': 2, 'G': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len 77510\n",
      "val len 12269\n",
      "test len 12107\n",
      "diff entries in train 55906\n",
      "same entries train 21604\n",
      "diff entries in val 1450\n",
      "same entries val 10819\n",
      "diff entries in test 1507\n",
      "same entries test 10600\n",
      "total train + dev + test\n",
      "101886\n",
      "max len in 351\n",
      "max len out 351\n",
      "one train entry ['ACAGAGGGGGCAAGCGTTGTCCGGAGTTACTGGGCGTAAAGGGCGCGCAGGCGGTGGGCTGCGTCGGCGCTGAAAGCGCCCCGCTTAACGGGGCGAGGCGCGCCGATACGAGTCCACTCGAGGCAAGCAGAGGGTGGCGGAATTCCGGGTGGAGTGGTGAAATGCGTAGAGATCCGGAGGAACGCCGGTGGGGAAGCCGGCCACCTGGGCTTGACCTGACGCTGCGGCGCGACAGCGTGGGGAGCAAACCG', 'ACAGAGGGGGCAAGCGTTGTCCGGAGTTACTGGGCGTAAAGGGCGCGCAGGCGGTGGGCTGCGTCGGCGCTGAAAGCGCCCCGCTTAACGGGGCGAGGCGCGCCGATACGAGTCCACTCGAGGCAAGCAGAGGGTGGCGGAATTCCGGGTGGAGCGGTGAAATGCGTAGAGATCCGGAGGAACGCCGGTGGGGAAGCCGGCCACCTGGGCTTGACCTGACGCTGCGGCGCGACAGCGTGGGGAGCAAACCG']\n"
     ]
    }
   ],
   "source": [
    "#Checkpoint prints\n",
    "#prints\n",
    "print(\"train len\",len(train_entries))\n",
    "print(\"val len\",len(val_entries))\n",
    "print(\"test len\",len(test_entries))\n",
    "print(\"diff entries in train\", count_diff_entries_train)\n",
    "print(\"same entries train\", count_same_entries_train)\n",
    "print(\"diff entries in val\", count_diff_entries_val)\n",
    "print(\"same entries val\", count_same_entries_val)\n",
    "print(\"diff entries in test\", count_diff_entries_test)\n",
    "print(\"same entries test\", count_same_entries_test)\n",
    "\n",
    "print(\"total train + dev + test\")\n",
    "print(len(train_entries)+ len(val_entries)+ len(test_entries))\n",
    "\n",
    "print(\"max len in\",max_length_in)\n",
    "print(\"max len out\", max_length_out)\n",
    "\n",
    "print(\"one train entry\",train_entries[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs= [entry[0] for entry in train_entries]\n",
    "output_seqs= [entry[1] for entry in train_entries]\n",
    "val_input_seqs= [entry[0] for entry in val_entries]\n",
    "val_output_seqs= [entry[1] for entry in val_entries]\n",
    "test_input_seqs= [entry[0] for entry in test_entries]\n",
    "test_output_seqs= [entry[1] for entry in test_entries]\n",
    "#display\n",
    "#print(\"train in\")\n",
    "#print(input_seqs[100])\n",
    "#print(\"val in\")\n",
    "#print(val_input_seqs[100])\n",
    "#print(\"test in\")\n",
    "#print(test_input_seqs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77510\n",
      "77510\n",
      "12269\n",
      "12107\n"
     ]
    }
   ],
   "source": [
    "print(len(input_seqs))\n",
    "print(len(output_seqs))\n",
    "print(len(val_input_seqs))\n",
    "print(len(test_input_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels len 77510\n",
      "val labels len 12269\n",
      "test labels len 12107\n"
     ]
    }
   ],
   "source": [
    "labels_train= [[1]]* count_diff_entries_train + [[-1]]*count_same_entries_train\n",
    "labels_val= [[1]]* count_diff_entries_val + [[-1]]*count_same_entries_val\n",
    "labels_test= [[1]]* count_diff_entries_test + [[-1]]*count_same_entries_test\n",
    "print(\"train labels len\",len(labels_train))\n",
    "print(\"val labels len\",len(labels_val))\n",
    "print(\"test labels len\",len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:\n",
      "input_seqs-> 77510\n",
      "output_seqs -> 77510\n",
      "labels train--> 77510\n"
     ]
    }
   ],
   "source": [
    "c = list(zip(input_seqs, output_seqs, labels_train))\n",
    "#seed = 123\n",
    "#random.seed(seed)\n",
    "#random.shuffle(c)\n",
    "input_seqs, output_seqs, labels_train = zip(*c)\n",
    "print(\"lengths:\")\n",
    "print(\"input_seqs->\",len(input_seqs))\n",
    "print(\"output_seqs ->\", len(output_seqs))\n",
    "print(\"labels train-->\", len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:\n",
      "input_seqs-> 12269\n",
      "output_seqs -> 12269\n",
      "labels train--> 12269\n"
     ]
    }
   ],
   "source": [
    "print(\"lengths:\")\n",
    "print(\"input_seqs->\",len(val_input_seqs))\n",
    "print(\"output_seqs ->\", len(val_output_seqs))\n",
    "print(\"labels train-->\", len(labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:\n",
      "input_seqs-> 12107\n",
      "output_seqs -> 12107\n",
      "labels train--> 12107\n"
     ]
    }
   ],
   "source": [
    "print(\"lengths:\")\n",
    "print(\"input_seqs->\",len(test_input_seqs))\n",
    "print(\"output_seqs ->\", len(test_output_seqs))\n",
    "print(\"labels train-->\", len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode train data\n",
    "\n",
    "#ENCODE\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_seqs), max_length_in, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_seqs, output_seqs) in enumerate(zip(input_seqs, output_seqs)):\n",
    "    for t, char in enumerate(input_seqs):\n",
    "        #print(t)\n",
    "        encoder_input_data[i, t, one_hot_input[char]] = 1.\n",
    "    for t, char in enumerate(output_seqs):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, one_hot_input[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, one_hot_input[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77510, 351, 5)\n",
      "(77510, 351, 5)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode val data\n",
    "\n",
    "#ENCODE\n",
    "encoder_input_data_val = np.zeros(\n",
    "    (len(val_input_seqs), max_length_in, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_input_data_val = np.zeros(\n",
    "    (len(val_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_target_data_val = np.zeros(\n",
    "    (len(val_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (val_input_seqs, val_output_seqs) in enumerate(zip(val_input_seqs, val_output_seqs)):\n",
    "    for t, char in enumerate(val_input_seqs):\n",
    "        #print(t)\n",
    "        encoder_input_data_val[i, t, one_hot_input[char]] = 1.\n",
    "    for t, char in enumerate(val_output_seqs):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_val[i, t, one_hot_input[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data_val[i, t - 1, one_hot_input[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12269, 351, 5)\n",
      "(12269, 351, 5)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_val.shape)\n",
    "print(decoder_input_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode test data\n",
    "\n",
    "#ENCODE\n",
    "encoder_input_data_test = np.zeros(\n",
    "    (len(test_input_seqs), max_length_in, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_input_data_test = np.zeros(\n",
    "    (len(test_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "decoder_target_data_test = np.zeros(\n",
    "    (len(test_input_seqs), max_length_out, len(one_hot_input)),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (test_input_seqs, test_output_seqs) in enumerate(zip(test_input_seqs, test_output_seqs)):\n",
    "    for t, char in enumerate(test_input_seqs):\n",
    "        #print(t)\n",
    "        encoder_input_data_test[i, t, one_hot_input[char]] = 1.\n",
    "    for t, char in enumerate(test_output_seqs):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_test[i, t, one_hot_input[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data_test[i, t - 1, one_hot_input[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12107, 351, 5)\n",
      "(12107, 351, 5)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_test.shape)\n",
    "print(decoder_input_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters to change\n",
    "num_encoder_tokens = len(one_hot_input)\n",
    "num_decoder_tokens = len(one_hot_input)\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "e_lstm_1 = Bidirectional(LSTM(latent_dim, return_sequences = True))(encoder_inputs)\n",
    "e_dropout = Dropout(0.5)(e_lstm_1)\n",
    "e_lstm_2, fh2, fc2, bh2, bc2 = Bidirectional(LSTM(latent_dim, return_sequences = True, return_state=True))(e_dropout)\n",
    "#e_lstm_3 = Bidirectional(LSTM(latent_dim, return_sequences = True))\n",
    "h2=Concatenate()([fh2,bh2])\n",
    "c2=Concatenate()([fc2,bc2])\n",
    "\n",
    "timed_output = TimeDistributed(Dense(num_decoder_tokens, activation = \"softmax\"))(e_lstm_2)\n",
    "noise_class = Dense(1, activation = \"tanh\")(Concatenate()([h2, c2]))\n",
    "#noise_class = Activation(\"tanh\")(noise_class)\n",
    "#print(noise_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_1/Reshape_1:0\", shape=(?, ?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(timed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 5)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 200)    84800       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 200)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, None, 200),  240800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 400)          0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 5)      1005        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            401         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 327,006\n",
      "Trainable params: 327,006\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Model(encoder_inputs, outputs=[timed_output,noise_class])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr = .001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "weight_nucleotide=1.\n",
    "weight_noise= 0.2\n",
    "model.compile(optimizer= adam, loss=['categorical_crossentropy','binary_crossentropy'], metrics = ['accuracy'], loss_weights=[weight_nucleotide, weight_noise])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: for the cell below\n",
    "#1. Modelcheckpoint doesn't take multiple arguments as a list to 'monitor', since what it does is basically check whethter the\n",
    "# quantity to monitor has improved over the last epoch and save the model\n",
    "#2.Specify the val accuracy corresponding to the output you care\n",
    "#3. file path also should have the same val_accuracy\n",
    "#4. Working on performing something like having a single loss function (as an average or something) instead of two loss functions \n",
    "# right now. Then we'll need only one val_accuracy. Right now don't think avg loss is a better idea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 1.1313 - time_distributed_1_loss: 1.0563 - dense_2_loss: 0.3753 - time_distributed_1_acc: 0.2594 - dense_2_acc: 1.0000 - val_loss: 1.0436 - val_time_distributed_1_loss: 1.0183 - val_dense_2_loss: 0.1269 - val_time_distributed_1_acc: 0.2528 - val_dense_2_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_time_distributed_1_acc improved from -inf to 0.25281, saving model to seqWeights/MultiLossLSTM-test-01-0.25.hdf5\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 1.0222 - time_distributed_1_loss: 1.0052 - dense_2_loss: 0.0849 - time_distributed_1_acc: 0.2574 - dense_2_acc: 1.0000 - val_loss: 0.9949 - val_time_distributed_1_loss: 0.9929 - val_dense_2_loss: 0.0099 - val_time_distributed_1_acc: 0.2527 - val_dense_2_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_time_distributed_1_acc did not improve from 0.25281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16bc3c49b70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = History()\n",
    "filepath=\"seqWeights/MultiLossLSTM-test-{epoch:02d}-{val_time_distributed_1_acc:.2f}.hdf5\"\n",
    "monitor_param='val_time_distributed_1_acc'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=monitor_param, verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "numExamples = 200\n",
    "batch_size = 100\n",
    "epochs = 2\n",
    "model.fit(encoder_input_data[0:numExamples, :, :],\n",
    "          [decoder_input_data[0:numExamples, :, :],np.array(labels_train)[0:numExamples]],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(encoder_input_data_val[0:numExamples,:,:],[decoder_input_data_val[0:numExamples, :, :],np.array(labels_val)[0:numExamples]]), verbose = 1,\n",
    "          callbacks = [history, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score= model.evaluate(encoder_input_data_test[0:numExamples,:,:], np.array(labels_test)[0:numExamples], verbose=0)\n",
    "print(\"scores\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.22730513, 0.22640508, 0.19525397, 0.25066787, 0.10036795],\n",
      "        [0.22786762, 0.21644306, 0.19795269, 0.2677272 , 0.0900095 ],\n",
      "        [0.22909367, 0.20407104, 0.1948256 , 0.29134625, 0.08066343],\n",
      "        ...,\n",
      "        [0.20849599, 0.19009958, 0.2028314 , 0.22064136, 0.17793164],\n",
      "        [0.2079552 , 0.18991601, 0.20310672, 0.21937504, 0.17964701],\n",
      "        [0.20739338, 0.18975265, 0.20344767, 0.21792847, 0.18147786]],\n",
      "\n",
      "       [[0.2274647 , 0.22510116, 0.1947394 , 0.24727607, 0.10541873],\n",
      "        [0.22870563, 0.21772306, 0.19721518, 0.26146945, 0.09488663],\n",
      "        [0.23089944, 0.20865302, 0.19431643, 0.28084564, 0.08528544],\n",
      "        ...,\n",
      "        [0.20849599, 0.19009955, 0.20283139, 0.22064136, 0.17793162],\n",
      "        [0.2079552 , 0.18991598, 0.2031067 , 0.21937504, 0.179647  ],\n",
      "        [0.20739336, 0.18975264, 0.20344765, 0.21792847, 0.18147784]]],\n",
      "      dtype=float32), array([[0.99162036],\n",
      "       [0.9874339 ]], dtype=float32)]\n",
      "[[1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(encoder_input_data_test[0:2, :, :]))\n",
    "print(np.array(labels_test)[0:2])\n",
    "#need to work on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
