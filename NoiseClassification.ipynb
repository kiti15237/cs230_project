{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ctata\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import loads done\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import History \n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Concatenate\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "from termcolor import colored\n",
    "\n",
    "from keras.activations import softmax \n",
    "print(\"import loads done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1dconv(window_size, filter_len, n_inp_series=1, n_output=1, n_filter=4):\n",
    "    model= Sequential()\n",
    "    model.add(Conv1D(filters= n_filter, kernel_size= filter_len, activation=\"relu\", input_shape=(window_size, n_inp_series)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(filters=n_filter, kernel_size=filter_len, activation=\"relu\"))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_output, activation=\"tanh\"))\n",
    "    \n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 48, 4)             64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 24, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 22, 4)             52        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 11, 4)             0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 225       \n",
      "=================================================================\n",
      "Total params: 341\n",
      "Trainable params: 341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#run the cell if want to progress using 1d conv model\n",
    "model= model_1dconv(window_size=50, filter_len= 3, n_inp_series=5, n_output=5, n_filter=4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath= \"blast_tab_1hit.out\"\n",
    "\n",
    "file= open(datapath, 'r')\n",
    "\n",
    "train_entries=[]\n",
    "val_entries= []\n",
    "test_entries=[]\n",
    "max_length_in =0\n",
    "max_length_out=0\n",
    "ynoise_train=[]\n",
    "ynoise_val=[]\n",
    "ynoise_test=[]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for ln in file:\n",
    "    toks=ln.split('\\t')\n",
    "    rand_num= np.random.random()\n",
    "    \n",
    "    if(toks[2] != toks[3]):\n",
    "        max_length_in= max(max_length_in, len(toks[2]))\n",
    "        max_length_out= max(max_length_out, len(toks[3]))\n",
    "        \n",
    "        if rand_num< 0.95:\n",
    "            train_entries.append([toks[2], toks[3]])\n",
    "            ynoise_train.append([1])\n",
    "        elif rand_num < 0.975:\n",
    "            test_entries.append([toks[2], toks[3]])\n",
    "            ynoise_test.append([1])\n",
    "        else:\n",
    "            val_entries.append([toks[2], toks[3]])\n",
    "            ynoise_val.append([1])\n",
    "    \n",
    "    if(toks[2]== toks[3]):\n",
    "        if rand_num > 0.975:\n",
    "            val_entries.append([toks[2], toks[3]])\n",
    "            ynoise_val.append([-1])\n",
    "        elif rand_num > 0.95:\n",
    "            test_entries.append([toks[2], toks[3]])\n",
    "            ynoise_test.append([-1])\n",
    "        elif rand_num > 0.9:\n",
    "            train_entries.append([toks[2], toks[3]])\n",
    "            ynoise_train.append([-1])\n",
    "            \n",
    "file.close()\n",
    "\n",
    "label_train_noise= np.array(ynoise_train)\n",
    "label_test_noise= np.array(ynoise_test)\n",
    "label_val_noise= np.array(ynoise_val)\n",
    "\n",
    "one_hot_input = {'A': 0, 'T': 1, 'C': 2, 'G': 3, '-': 4}\n",
    "one_hot_output = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape\n",
      "y_train:  (77510, 1)\n",
      "y_test:  (12107, 1)\n",
      "y_val:  (12269, 1)\n",
      "[[ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "#print shapes:\n",
    "print(\"labels shape\")\n",
    "print(\"y_train: \", label_train_noise.shape)\n",
    "print(\"y_test: \", label_test_noise.shape)\n",
    "print(\"y_val: \", label_val_noise.shape)\n",
    "print(label_train_noise[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualize labels for noisy vs non-noisy\n",
      "y_train\n",
      "[[ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]]\n",
      "y_val\n",
      "[[-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]]\n",
      "y_test\n",
      "[[-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "#visualize labels\n",
    "num_vis= 100\n",
    "print(\"visualize labels for noisy vs non-noisy\")\n",
    "print(\"y_train\")\n",
    "print(label_train_noise[0:num_vis])\n",
    "print(\"y_val\")\n",
    "print(label_val_noise[0:num_vis])\n",
    "print(\"y_test\")\n",
    "print(label_test_noise[0:num_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data entries:\n",
      "train\n",
      "['ACCGACGGCCCGAGTGGTGGCCACTTTTATTGGGCCTAAAGCGTCCGTAGCCGGTCCAGTAAGTCCTTGTTTAAATCCTGCGGCTTAACCGCAGGACTGGCAGGGATACTGCTGGACTTGGGACCGGGAGAGGACAAGGGTACTTCAGGGGTAGCGGTGAAATGTGTTGATCCTTGAAGGACCACCTATGGCGAAGGCACTTGTCTGGAACGGGTCCGACGGTGAGGGACGAAGGCCAGGGGAGCAAACCG', 'ACCGACGGCCCGAGTGGTGGCCACTTTTATTGGGCCTAAAGCGTCCGTAGCCGGTCCAGTAAGTCCTTGTTTAAATCCTGCGGCTTAACCGCAGGACTGGCAGGGATACTGCTGGACTTGGGACCGGGAGAGGACAAGGGTACTTCAGGGGTAGCGGTGAAATGTGTTGATCCTTGAAGGACCACCTATGGCGAAGGCACTTGTCTGGAACGGGTCCGACGGTGAGGGACGAAAGCCAGGGGCGCGAACCG']\n",
      "test\n",
      "['ACAGGGGTGGCAAGCGTTGTCCGGATTTACTGGGTGTAAAGGGTGCGCAGGCGGATTCATAAGTCGGGGGTTAAATCCATGTGCTTAACACATGCAAGGCTTCCGATACTGTGAGTCTAGAGTCTCGAAGAGGAAGATGGAATTTCCGGTGTAACGGTGGAATGTGTAGATATCGGAAAGAACACCAGTGGCGAAGGCAGTCTTCTGGTCGAGAACTGACGCTCAGGCACGAAAGCGTGGGGAGCAAACAG', 'ACAGGGGTGGCAAGCGTTGTCCGGATTTACTGGGTGTAAAGGGTGCGCAGGCGGATTCATAAGTCGGGGGTTAAATCCATGTGCTTAACACATGCAAGGCTTCCGATACTGTGAGTCTAGAGTCTCGAAGAGGAAGATGGAATTTCCGGTGTAACGGTGGAATGTGTAGATATCGGAAAGAACACCAGTGGCGAAGGCAGTCTTCTGGTCGAGAACTGACGCTCAGGCACGAAAGCGTGGGGAGCAAACAG']\n",
      "val\n",
      "['TAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCGCAGGCGGTTGTGTAAGACAGATGTGAAATCCCCGGGCTCAACCTGGGAACTGCATTTGTGACTGCACAGCTAGAGTACGGTAGAGGGGGATGGAATTCCGCGTGTAGCAGTGAAATGCGTAGATATGCGGAGGAACACCGATGGCGAAGGCAATCCCCTGGACCTGTACTGACGCTCATGCACGAAAGCGTGGGGAGCAAACAG', 'TAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCGCAGGCGGTTGTGTAAGACAGATGTGAAATCCCCGGGCTCAACCTGGGAACTGCATTTGTGACTGCACAGCTAGAGTACGGTAGAGGGGGATGGAATTCCGCGTGTAGCAGTGAAATGCGTAGATATGCGGAGGAACACCGATGGCGAAGGCAATCCCCTGGACCTGTACTGACGCTCATGCACGAAAGCGTGGGGAGCAAACAG']\n"
     ]
    }
   ],
   "source": [
    "#visualize data entries\n",
    "n_peek=10\n",
    "print(\"data entries:\")\n",
    "print(\"train\")\n",
    "print(train_entries[n_peek])\n",
    "\n",
    "print(\"test\")\n",
    "print(test_entries[n_peek])\n",
    "\n",
    "print(\"val\")\n",
    "print(val_entries[n_peek])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len inp: 308\n",
      "max len out:  308\n"
     ]
    }
   ],
   "source": [
    "#length of sequences\n",
    "print(\"max len inp:\", max_length_in)\n",
    "print(\"max len out: \", max_length_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes\n",
      "(77510, 1)\n",
      "(12107, 1)\n",
      "(12269, 1)\n"
     ]
    }
   ],
   "source": [
    "labels_train=np.array(label_train_noise)\n",
    "labels_val= np.array(label_val_noise)\n",
    "labels_test= np.array(label_test_noise)\n",
    "\n",
    "print(\"shapes\")\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next few cells used for data preparation\n",
    "#for train, val and test data to send inside model\n",
    "\n",
    "input_seqs= [entry[0] for entry in train_entries]\n",
    "output_seqs= [entry[1] for entry in train_entries]\n",
    "val_input_seqs= [entry[0] for entry in val_entries]\n",
    "val_output_seqs= [entry[1] for entry in val_entries]\n",
    "test_input_seqs= [entry[0] for entry in test_entries]\n",
    "test_output_seqs= [entry[1] for entry in test_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77510\n",
      "12269\n",
      "12107\n"
     ]
    }
   ],
   "source": [
    "print(len(input_seqs))\n",
    "print(len(val_input_seqs))\n",
    "print(len(test_input_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train val and test data\n",
    "X_train= np.zeros(\n",
    "    (len(input_seqs), len(one_hot_input), max_length_in, 1),\n",
    "    dtype= 'float32')\n",
    "#print(X_train.shape)\n",
    "for i, (input_seqs, output_seqs) in enumerate(zip(input_seqs, output_seqs)):\n",
    "    for t, char in enumerate(input_seqs):\n",
    "        X_train[i,one_hot_input[char],t,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77510, 5, 308, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_vis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-12da8b305c52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#shape and data for X_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_vis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'num_vis' is not defined"
     ]
    }
   ],
   "source": [
    "#shape and data for X_train\n",
    "print(X_train.shape)\n",
    "print(X_train[0:num_vis, :,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val data train\n",
    "X_val= np.zeros(\n",
    "    (len(val_input_seqs), len(one_hot_input), max_length_in, 1),\n",
    "    dtype= 'float32')\n",
    "#print(X_train.shape)\n",
    "for i, (val_input_seqs, val_output_seqs) in enumerate(zip(val_input_seqs, val_output_seqs)):\n",
    "    for t, char in enumerate(val_input_seqs):\n",
    "        X_val[i,one_hot_input[char],t,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12269, 5, 308, 1)\n",
      "[[[1. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "#shape and data for X_val\n",
    "print(X_val.shape)\n",
    "print(X_val[0:num_vis, :,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= np.zeros(\n",
    "    (len(test_input_seqs), len(one_hot_input), max_length_in, 1),\n",
    "    dtype= 'float32')\n",
    "#print(X_train.shape)\n",
    "for i, (test_input_seqs, test_output_seqs) in enumerate(zip(test_input_seqs, test_output_seqs)):\n",
    "    for t, char in enumerate(test_input_seqs):\n",
    "        X_test[i,one_hot_input[char],t,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12107, 5, 308, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape and data for X_test\n",
    "print(X_test.shape)\n",
    "print(X_test[0:num_vis, :,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softMaxAxis1(x):\n",
    "    return softmax(x,axis=1)\n",
    "\n",
    "\n",
    "def model_custom(input_shape):\n",
    "    X_input= Input(input_shape)\n",
    "    \n",
    "    X= Conv2D(128, (4,7), strides=(1,1), padding='same', name='conv0')(X_input)\n",
    "    X= BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X= Activation('relu')(X)\n",
    "    \n",
    "    X= Conv2D(64, (1,7), strides=(1,1), padding='same', name='conv1')(X)\n",
    "    X= BatchNormalization(axis=3, name='bn1')(X)\n",
    "    X= Activation('relu')(X)\n",
    "    \n",
    "    X= Conv2D(64, (1,7), strides=(1,1), padding='same', name='conv2')(X)\n",
    "    X= BatchNormalization(axis=3, name='bn2')(X)\n",
    "    X= Activation('relu')(X)\n",
    "    \n",
    "    X= Dropout(0.3, name='dropout')(X)\n",
    "    \n",
    "    X= Conv2D(32, (1,7), strides=(1,1), padding='same', name='conv3')(X)\n",
    "    X= BatchNormalization(axis=3, name='bn3')(X)\n",
    "    X= Activation('relu')(X)\n",
    "    \n",
    "    X= Conv2D(1, (1,1), strides=(1,1), padding='same', name='conv4')(X)\n",
    "    X= BatchNormalization(axis=3, name='bn4')(X)\n",
    "    X= Flatten()(X)\n",
    "    X= Dense(2, activation='softmax')(X)\n",
    "    \n",
    "    model= Model(inputs=X_input, outputs=X, name='Model1')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 5, 308, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 5, 308, 128)       3712      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 5, 308, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5, 308, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 5, 308, 64)        57408     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 5, 308, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 5, 308, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 5, 308, 64)        28736     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 5, 308, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5, 308, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 308, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 5, 308, 32)        14368     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 5, 308, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5, 308, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 5, 308, 1)         33        \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 5, 308, 1)         4         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1540)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 3082      \n",
      "=================================================================\n",
      "Total params: 108,495\n",
      "Trainable params: 107,917\n",
      "Non-trainable params: 578\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#need to pass in parameters from input data\n",
    "mymodel= model_custom((len(one_hot_input),max_length_in,1))\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation done!\n"
     ]
    }
   ],
   "source": [
    "#compile model\n",
    "adam= keras.optimizers.Adam(lr= 0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "mymodel.compile(optimizer= adam, loss= \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "print(\"compilation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False False  True  True False False]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels_unlist_train = np.array([i for sublist in labels_train for i in sublist])\n",
    "labels_onehot_train = np.zeros((len(labels_unlist_train), 2))\n",
    "labels_onehot_train[labels_unlist_train == 1, 0] = 1\n",
    "labels_onehot_train[labels_unlist_train == -1, 1] = 1\n",
    "\n",
    "labels_unlist_val = np.array([i for sublist in labels_val for i in sublist])\n",
    "labels_onehot_val = np.zeros((len(labels_unlist_val), 2))\n",
    "labels_onehot_val[labels_unlist_val == 1, 0] = 1\n",
    "labels_onehot_val[labels_unlist_val == -1, 1] = 1\n",
    "\n",
    "\n",
    "print(labels_unlist[0:10] == -1)\n",
    "print(labels_tmp[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77510, 5, 308, 1)\n",
      "(1000, 5, 308, 1)\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.7432 - acc: 0.6990 - val_loss: 1.1327 - val_acc: 0.4050\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.40500, saving model to seqWeights/ConvNet-test-01-0.40.hdf5\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.6980 - acc: 0.7090 - val_loss: 1.6643 - val_acc: 0.2810\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.40500\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 103s 103ms/step - loss: 0.6351 - acc: 0.7080 - val_loss: 1.2254 - val_acc: 0.3190\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.40500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.5689 - acc: 0.7290 - val_loss: 1.5405 - val_acc: 0.2040\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.40500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.5176 - acc: 0.7570 - val_loss: 1.6450 - val_acc: 0.1970\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.40500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 0.5427 - acc: 0.7400 - val_loss: 1.3571 - val_acc: 0.2550\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.40500\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.5348 - acc: 0.7440 - val_loss: 1.4397 - val_acc: 0.1910\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.40500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.5185 - acc: 0.7490 - val_loss: 1.4588 - val_acc: 0.1940\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.40500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 0.4991 - acc: 0.7560 - val_loss: 1.5211 - val_acc: 0.1940\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.40500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.4720 - acc: 0.7680 - val_loss: 1.3322 - val_acc: 0.1980\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.40500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x296b7bd7438>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run model\n",
    "history = History()\n",
    "filepath=\"seqWeights/ConvNet-test-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "numExamples = 1000\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "print(X_train.shape)\n",
    "print((X_train[0:numExamples,:,:,:]).shape)\n",
    "mymodel.fit(X_train[0:numExamples, :, :,:],\n",
    "          labels_onehot_train[0:numExamples],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_val[0:numExamples,:,:,:], labels_onehot_val[0:numExamples]), verbose = 1,\n",
    "         callbacks = [history, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 172s 86ms/step - loss: 0.5283 - acc: 0.7420 - val_loss: 1.7087 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00001: saving model to seqWeights/noise_class-01-0.15.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 176s 88ms/step - loss: 0.5360 - acc: 0.7285 - val_loss: 1.6123 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00002: saving model to seqWeights/noise_class-02-0.15.hdf5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 176s 88ms/step - loss: 0.5095 - acc: 0.7335 - val_loss: 1.4530 - val_acc: 0.1430\n",
      "\n",
      "Epoch 00003: saving model to seqWeights/noise_class-03-0.14.hdf5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 172s 86ms/step - loss: 0.4959 - acc: 0.7435 - val_loss: 1.1434 - val_acc: 0.2515\n",
      "\n",
      "Epoch 00004: saving model to seqWeights/noise_class-04-0.25.hdf5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 174s 87ms/step - loss: 0.4955 - acc: 0.7555 - val_loss: 1.2118 - val_acc: 0.1590\n",
      "\n",
      "Epoch 00005: saving model to seqWeights/noise_class-05-0.16.hdf5\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 173s 87ms/step - loss: 0.4976 - acc: 0.7445 - val_loss: 1.2474 - val_acc: 0.1590\n",
      "\n",
      "Epoch 00006: saving model to seqWeights/noise_class-06-0.16.hdf5\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 174s 87ms/step - loss: 0.4803 - acc: 0.7470 - val_loss: 1.3646 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00007: saving model to seqWeights/noise_class-07-0.15.hdf5\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 171s 86ms/step - loss: 0.4908 - acc: 0.7500 - val_loss: 1.2150 - val_acc: 0.1745\n",
      "\n",
      "Epoch 00008: saving model to seqWeights/noise_class-08-0.17.hdf5\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 174s 87ms/step - loss: 0.4908 - acc: 0.7435 - val_loss: 1.3081 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00009: saving model to seqWeights/noise_class-09-0.15.hdf5\n",
      "Epoch 10/10\n",
      " 800/2000 [===========>..................] - ETA: 1:25 - loss: 0.4942 - acc: 0.7388"
     ]
    }
   ],
   "source": [
    "mymodel.fit(X_train[0:numExamples, :, :,:],\n",
    "          labels_onehot_train[0:numExamples],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_val[0:numExamples,:,:,:], labels_onehot_val[0:numExamples]), verbose = 1,\n",
    "         callbacks = [history, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "currtime = datetime.datetime.now()\n",
    "histfname = \"./trainHistoryDict_\" + currtime.strftime(\"%m%d-%H%M\") + \"_5hotNoiseClassification\"\n",
    "with open(histfname, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "histfname = \"./trainHistoryDict_\" + \"0605-2259\" + \"_5hotNoiseClassification\"\n",
    "history = pickle.load(open(histfname, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mymodel.predict(X_train[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9955004e-01 4.4997918e-04]\n",
      " [9.3017083e-01 6.9829136e-02]\n",
      " [9.9486959e-01 5.1304027e-03]\n",
      " [2.1925326e-01 7.8074670e-01]\n",
      " [8.1165135e-01 1.8834871e-01]\n",
      " [9.4235069e-01 5.7649311e-02]\n",
      " [3.3465210e-02 9.6653485e-01]\n",
      " [3.3735335e-01 6.6264665e-01]\n",
      " [7.4054539e-01 2.5945464e-01]\n",
      " [5.3009051e-01 4.6990946e-01]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(preds[0:10])\n",
    "print(labels_onehot_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_input = {'A': 0, 'C': 1, 'G': 2, 'T': 3, '-': 4}\n",
    "num_encoder_tokens = len(one_hot_input)\n",
    "num_decoder_tokens = len(one_hot_input)\n",
    "latent_dim = 100\n",
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "e_lstm_1 = Bidirectional(LSTM(latent_dim, return_sequences = True))(encoder_inputs)\n",
    "e_dropout = Dropout(0.5)(e_lstm_1)\n",
    "e_lstm_2 = Bidirectional(LSTM(latent_dim, return_sequences = False))(e_dropout)\n",
    "#e_lstm_3 = Bidirectional(LSTM(latent_dim, return_sequences = True))\n",
    "\n",
    "noise_class = Dense(2, activation = \"softmax\")(e_lstm_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 121s 61ms/step - loss: 0.6081 - acc: 0.7645 - val_loss: 0.9660 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00001: saving model to seqWeights/noise_class-01-0.15.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 123s 61ms/step - loss: 0.5599 - acc: 0.7685 - val_loss: 1.0955 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00002: saving model to seqWeights/noise_class-02-0.15.hdf5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 128s 64ms/step - loss: 0.5468 - acc: 0.7685 - val_loss: 1.1759 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00003: saving model to seqWeights/noise_class-03-0.15.hdf5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 131s 66ms/step - loss: 0.5434 - acc: 0.7685 - val_loss: 1.2293 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00004: saving model to seqWeights/noise_class-04-0.15.hdf5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 128s 64ms/step - loss: 0.5424 - acc: 0.7685 - val_loss: 1.2470 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00005: saving model to seqWeights/noise_class-05-0.15.hdf5\n",
      "Epoch 6/10\n",
      "1000/2000 [==============>...............] - ETA: 58s - loss: 0.5510 - acc: 0.7590 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-fe2def0de4bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnumExamples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_onehot_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnumExamples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m          callbacks = [history, checkpoint])\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_seq = Model(encoder_inputs, noise_class)\n",
    "\n",
    "#model_seq.load_weights(\"seqWeights/LSTM-test-comboseqs-dropout0.5-manytomany-11-0.83.hdf5\")\n",
    "adam = keras.optimizers.Adam(lr = .001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.95, amsgrad=False)\n",
    "model_seq.compile(optimizer= adam, loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = History()\n",
    "filepath=\"seqWeights/noise_class-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only= False, mode='max')\n",
    "\n",
    "numExamples = 2000\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "#output_seqs = decoder_input_data[0:numExamples, :, :]\n",
    "#y = output_seqs.reshape(numExamples, output_seqs.shape[1], 1)\n",
    "model_seq.fit(np.swapaxes(np.squeeze(X_train[0:numExamples, :, :,:]), 1, 2),\n",
    "          labels_onehot_train[0:numExamples],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(np.swapaxes(np.squeeze(X_val[0:numExamples,:,:,:]), 1, 2), labels_onehot_val[0:numExamples]), verbose = 1,\n",
    "         callbacks = [history, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_seq = model_seq.predict(np.swapaxes(np.squeeze(X_train[0:numExamples, :, :,:]), 1, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
